<html>
  I began by downloading the data folder that contained all the phrases we are going to use for the bot.
  I then used three different functions to split each phrase in the file and group them together as a sentence, which was then extracted into the database.
  It then calls the functions and creates the data file for the phrases.
  I next use some class functions to create a vocabulary, and query each response to an input.
  I then used a MIN function to trim out the excess words that would be hardly used.
  I then used multiple different functions to transform the character input into binary that the bot would understand, then transform his response back into character.
  I then used a variety of different input and output methods to convert different word indexes into embeddings, which would pack them through to the GRU.
  I then wrote a decoder class function to generate the bot's response in a token-by-token fashion.
  I then wrote a training procedure for the bot that would teach it how to respond to different phrases using many pytorch functions, such as the "train" command.
</html>
